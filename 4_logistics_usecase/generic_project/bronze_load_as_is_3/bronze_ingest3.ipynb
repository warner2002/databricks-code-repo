{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c6ee6c-5768-4991-a40c-59d36696c418",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Enterprise Fleet Analytics Pipeline: Focuses on the business outcome (analytics) and the domain (fleet/logistics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5283002-4456-4789-84f5-f7c215f4edf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](/Workspace/Users/infoblisstech@gmail.com/databricks-code-repo/4_logistics_usecase/generic_project/general_conf_utils_1_2/medallion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3904d0a1-6202-481e-b679-313d78fc00cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\",\"\")\n",
    "CATALOG=dbutils.widgets.get(\"catalog\").strip()\n",
    "dbutils.widgets.text(\"schema\",\"\")\n",
    "SCHEMA=dbutils.widgets.get(\"schema\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e379d955-738f-4926-8a20-86c4c9bd5ed9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#As we are parameterizing, we don't need to hardcode, which is not production ready..\n",
    "#CATALOG='prodcatalog'\n",
    "#SCHEMA='logistics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44951ae5-06a7-4493-b28c-82081c530784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Setting generic configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7659f0d-9b75-4d1d-83ac-24f8590ee7f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import json\n",
    "#IMPORTANT DATABRICKS INTERVIEW QUESITON: When I run a notebook using dbutils.notebook.run(notebook,maxrunseconds,paramerters as dictionary)\n",
    "#1. It will run the notebook in the respective folder/instance/autonomously (hence we don't get in the parent notebook, all the variables/values set in the child notebook). If we use %run, the child notebook variable/values can be accessed in the parent notebook directly because it runs inline/within the parent notebook scope.\n",
    "#2. Using dbutils.notebook.run(notebook,maxrunseconds,paramerters as dictionary) - we can pass parameters to the child notebook, but %run will not allow us to pass params\n",
    "config_nb_output = dbutils.notebook.run(\n",
    "    \"/Workspace/Users/infoblisstech@gmail.com/databricks-code-repo/4_logistics_usecase/generic_project/general_conf_utils_1_2/configs_path1\",\n",
    "    120,{\"catalog\": CATALOG,\"schema\": SCHEMA})\n",
    "#print(SRC)#this will throw error\n",
    "\n",
    "config_dict = json.loads(config_nb_output)\n",
    "print(config_dict)\n",
    "\n",
    "#CATALOG = config_dict[\"CATALOG\"]\n",
    "#SCHEMA = config_dict[\"SCHEMA\"]\n",
    "SRC=config_dict[\"SRC\"]\n",
    "BRONZE = config_dict[\"BRONZE\"]\n",
    "#SILVER = config_dict[\"SILVER\"]\n",
    "#GOLD = config_dict[\"GOLD\"]\n",
    "#SILVERDB = config_dict[\"SILVERDB\"]\n",
    "#GOLDDB = config_dict[\"GOLDDB\"]\n",
    "\n",
    "print(\"returned source location is \",SRC)\n",
    "print(\"returned target bronze location is \",BRONZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f324709a-7990-4dd4-bdba-eb62e79eb57e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb1de163-2364-49e6-a86d-a84a991103d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/infoblisstech@gmail.com/databricks-code-repo/4_logistics_usecase/generic_project/general_conf_utils_1_2/util_functions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70faf043-937f-4671-ae2e-137f25c5477a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Starting the Bronze layer execution - Read data from source (SRC) datalake and load into target datalake (bronze volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d64cb575-fb3e-47b5-9b8d-7c707793ee38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Adapting Generic Framework\n",
    "spark=get_spark_session(\"Logistics Data Engineering Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c772dac2-29cd-422c-bddf-712556807cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#No Adoption of Generic Framework (Inline programming)\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Logistics Data Engineering Project\").getOrCreate()\n",
    "'''\n",
    "We lost all the below features...\n",
    "    Centralized and controllable\n",
    "    Production Ready\n",
    "    Reusability\n",
    "    Seperation of Concern\n",
    "    Modularized\n",
    "    Simple to write/Reasonable to understand\n",
    "    Optimization\n",
    "    Governed\n",
    "    Secured\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe923192-71a4-4447-9443-74b6e48faa49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#All Read ops\n",
    "#Staff data read operations\n",
    "#inline coding\n",
    "#staff1=spark.read.csv(f\"{SRC}/logistics_source1.txt\",header=True,inferSchema=True)\n",
    "#inline functions\n",
    "#def fun1():\n",
    "#    return spark.read.csv(f\"{SRC}/logistics_source2.txt\",header=True,inferSchema=True)\n",
    "\n",
    "#or better prod standard approach is calling the generic framework\n",
    "staff1=read_file(spark,'csv',f\"{SRC}/logistics_source1.txt\",True,False)#Referring the program, rather than writing it inline\n",
    "staff2=read_csv_df(spark,f\"{SRC}/logistics_source2.txt\",True,False)\n",
    "#print(staff1.schema)\n",
    "#print(staff2.schema)\n",
    "\n",
    "#staff_bronze_same_structure=unionDf(staff1,staff2)#Needed if the EDA output says both data sources have same structure\n",
    "#staff_bronze_same_structure=staff1.union(staff2)\n",
    "'''view1=staff1+\"_view\"\n",
    "view2=staff2+\"_view\"\n",
    "df1.createOrReplaceTempView(view1)\n",
    "df2.createOrReplaceTempView(view2)\n",
    "staff_bronze=unionDfSql(spark,view1,view2)\n",
    "'''\n",
    "staff_bronze=mergeDf(staff1,staff2) #Needed if the EDA output says both data sources have different structure\n",
    "\n",
    "#Geo tagging data read operations\n",
    "geo_tagging=read_csv_df(spark,f\"{SRC}/Master_City_List.csv\",True,False)\n",
    "\n",
    "#Shipment data read operations\n",
    "shipments_bronze = read_json_df(spark,f\"{SRC}/logistics_shipment_detail_3000.json\",True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96aa7eb3-b7c1-4b2f-8891-8231bb30df4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#All Read ops from Source Datalake/any other sources\n",
    "#Staff data read operations\n",
    "staff1=read_file(spark,'csv',f\"{SRC}/logistics_source1.txt\",True,False)\n",
    "staff2=read_csv_df(spark,f\"{SRC}/logistics_source2.txt\",True,False)\n",
    "staff_bronze=mergeDf(staff1,staff2)\n",
    "geo_tagging=read_csv_df(spark,f\"{SRC}/Master_City_List.csv\",True,False)\n",
    "shipments_bronze = read_json_df(spark,f\"{SRC}/logistics_shipment_detail_3000.json\",True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "024b8ecb-924e-4bfb-b3bd-88da6e2873f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#All Write ops (from source datalake to the bronze layer (datalake))\n",
    "#write_file(staff_bronze, f\"{BRONZE}/staff\", mode=\"overwrite\", format=\"json\")\n",
    "write_file(staff_bronze, f\"{BRONZE}/staff\", mode=\"overwrite\", format=\"delta\")#datalake\n",
    "#write_table(staff_bronze, 'bronze_staff_table')#lakehouse (we don't do it in bronze layer in general, but in a case our Data governance team wanted to analyse/EDA the raw data in bronze layer)\n",
    "write_file(geo_tagging, f\"{BRONZE}/geotag\", mode=\"overwrite\", format=\"delta\")\n",
    "#write_file(geo_tagging, f\"{BRONZE}/geotag/csvfolder\", mode=\"overwrite\", format=\"csv\")\n",
    "write_file(shipments_bronze, f\"{BRONZE}/shipments\", mode=\"overwrite\", format=\"delta\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingest3",
   "widgets": {
    "catalog": {
     "currentValue": "catalog2_we47",
     "nuid": "a23d3dc3-bdc7-478f-b60c-ecec8ad9d84b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "schema2_we47",
     "nuid": "7fea26dc-2a97-4823-8004-998ec28ab1d3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
